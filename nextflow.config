// DIANN Workflow - Base Configuration
// Compatible with Nextflow DSL2

// Enable DSL2
nextflow.enable.dsl = 2

// Default parameters - can be overridden via config files or command line
params {
    // Container settings
    container_registry = 'quay.io/karlssoc/diann'
    diann_version = '2.3.1'

    // Default resource settings
    threads = 60

    // Parallel execution mode (for 60-core systems)
    // When true: runs 2 jobs at 30 cores each for better throughput
    // When false: runs 1 job at 60 cores for maximum per-job speed
    parallel_mode = true

    // Output directory
    outdir = 'results'

    // SLURM settings (can be overridden)
    slurm_account = null
    slurm_queue = null  // IMPORTANT: Set this if your SLURM requires a partition (-p flag)
                        // Example: slurm_queue = 'long' for long-running jobs
                        // Without this, jobs may fail or use restrictive default partition

    // Optional model files for tuned workflows
    tokens = null
    rt_model = null
    im_model = null
    fr_model = null

    // Optional workflow parameters
    library = null
    subdir = null
    ref_library = null          // Reference library for batch calibration

    // Dynamic time allocation for quantify jobs
    time_base_hours = 2         // Base time in hours
    time_per_file_minutes = 10  // Additional time per MS file (accounts for variability)

    // Ultrafast quantification mode (trades some sensitivity for speed)
    ultrafast = false

    // Batch correction parameters (for multi-batch data from same instrument)
    individual_windows = false  // Use individual RT windows per run

    // Help message
    help = false
}

// Container configuration (enabled per-profile below)
// singularity {
//     enabled = true
//     autoMounts = true
//     cacheDir = "${HOME}/.singularity/cache"
// }

docker {
    enabled = false
}

// Process defaults
process {
    // Default container for all processes
    container = "${params.container_registry}:${params.diann_version}"

    // Error strategy
    errorStrategy = 'retry'
    maxRetries = 2

    // Default resources
    cpus = 1
    memory = '4 GB'
    time = '1h'
}

// Execution profiles
profiles {
    standard {
        process.executor = 'local'
        singularity {
            enabled = true
            autoMounts = true
            cacheDir = "${HOME}/.singularity/cache"
        }
    }

    slurm {
        singularity {
            enabled = true
            autoMounts = true
            cacheDir = "${HOME}/.singularity/cache"
        }

        executor {
            name = 'slurm'
            queueSize = { params.parallel_mode ? 4 : 2 }  // More concurrent jobs in parallel mode
            exitReadTimeout = '10 min'  // Time to wait for SLURM to provide exit status
            pollInterval = '1 min'  // Check job status every minute
            queueStatInterval = '2 min'  // Check queue state every 2 minutes
            submitRateLimit = '5 / 1 sec'  // Throttle job submissions
        }

        process {
            executor = 'slurm'
            queue = params.slurm_queue
            clusterOptions = params.slurm_account ? "--account=${params.slurm_account}" : ''

            // Process-specific resources
            withLabel: 'diann_tune' {
                cpus = 10  // Tuning is not CPU-intensive, keep at 10
                memory = '10 GB'
                time = '2h'
            }

            withLabel: 'diann_library' {
                // Parallel mode: 30 cores allows 2 jobs concurrently (60 total)
                // Sequential mode: 60 cores for maximum speed per job
                cpus = { params.parallel_mode ? 30 : params.threads }
                memory = { params.parallel_mode ? '20 GB' : '30 GB' }
                time = '4h'
                maxForks = { params.parallel_mode ? 2 : 1 }
            }

            withLabel: 'diann_quantify' {
                // Parallel mode: 30 cores allows 2 samples concurrently (60 total)
                // Sequential mode: 60 cores for maximum speed per sample
                cpus = { params.parallel_mode ? 30 : params.threads }
                memory = { params.parallel_mode ? (15.GB) : (500.MB * params.threads) }
                // Note: time is dynamically calculated per job based on file count
                // Formula: time_base_hours + (file_count * time_per_file_minutes)
                // This fallback is only used if dynamic calculation fails
                time = '8h'
                maxForks = { params.parallel_mode ? 2 : 1 }
            }
        }
    }

    docker {
        process.executor = 'local'
        docker {
            enabled = true
            runOptions = '-u $(id -u):$(id -g) --platform linux/amd64'
        }
    }

    docker_slurm {
        docker {
            enabled = true
            runOptions = '-u $(id -u):$(id -g) --platform linux/amd64'
        }

        executor {
            name = 'slurm'
            queueSize = { params.parallel_mode ? 4 : 2 }  // More concurrent jobs in parallel mode
            exitReadTimeout = '10 min'  // Time to wait for SLURM to provide exit status
            pollInterval = '1 min'  // Check job status every minute
            queueStatInterval = '2 min'  // Check queue state every 2 minutes
            submitRateLimit = '5 / 1 sec'  // Throttle job submissions
        }

        process {
            executor = 'slurm'
            queue = params.slurm_queue
            clusterOptions = params.slurm_account ? "--account=${params.slurm_account}" : ''

            // Process-specific resources
            withLabel: 'diann_tune' {
                cpus = 10  // Tuning is not CPU-intensive, keep at 10
                memory = '10 GB'
                time = '2h'
            }

            withLabel: 'diann_library' {
                // Parallel mode: 30 cores allows 2 jobs concurrently (60 total)
                // Sequential mode: 60 cores for maximum speed per job
                cpus = { params.parallel_mode ? 30 : params.threads }
                memory = { params.parallel_mode ? '20 GB' : '30 GB' }
                time = '4h'
                maxForks = { params.parallel_mode ? 2 : 1 }
            }

            withLabel: 'diann_quantify' {
                // Parallel mode: 30 cores allows 2 samples concurrently (60 total)
                // Sequential mode: 60 cores for maximum speed per sample
                cpus = { params.parallel_mode ? 30 : params.threads }
                memory = { params.parallel_mode ? (15.GB) : (500.MB * params.threads) }
                // Note: time is dynamically calculated per job based on file count
                // Formula: time_base_hours + (file_count * time_per_file_minutes)
                // This fallback is only used if dynamic calculation fails
                time = '8h'
                maxForks = { params.parallel_mode ? 2 : 1 }
            }
        }
    }

    podman {
        process.executor = 'local'
        podman {
            enabled = true
        }
    }

    podman_slurm {
        podman {
            enabled = true
        }

        executor {
            name = 'slurm'
            queueSize = { params.parallel_mode ? 4 : 2 }  // More concurrent jobs in parallel mode
            exitReadTimeout = '10 min'  // Time to wait for SLURM to provide exit status
            pollInterval = '1 min'  // Check job status every minute
            queueStatInterval = '2 min'  // Check queue state every 2 minutes
            submitRateLimit = '5 / 1 sec'  // Throttle job submissions
        }

        process {
            executor = 'slurm'
            queue = params.slurm_queue
            clusterOptions = params.slurm_account ? "--account=${params.slurm_account}" : ''

            // Process-specific resources
            withLabel: 'diann_tune' {
                cpus = 10  // Tuning is not CPU-intensive, keep at 10
                memory = '10 GB'
                time = '2h'
            }

            withLabel: 'diann_library' {
                // Parallel mode: 30 cores allows 2 jobs concurrently (60 total)
                // Sequential mode: 60 cores for maximum speed per job
                cpus = { params.parallel_mode ? 30 : params.threads }
                memory = { params.parallel_mode ? '20 GB' : '30 GB' }
                time = '4h'
                maxForks = { params.parallel_mode ? 2 : 1 }
            }

            withLabel: 'diann_quantify' {
                // Parallel mode: 30 cores allows 2 samples concurrently (60 total)
                // Sequential mode: 60 cores for maximum speed per sample
                cpus = { params.parallel_mode ? 30 : params.threads }
                memory = { params.parallel_mode ? (15.GB) : (500.MB * params.threads) }
                // Note: time is dynamically calculated per job based on file count
                // Formula: time_base_hours + (file_count * time_per_file_minutes)
                // This fallback is only used if dynamic calculation fails
                time = '8h'
                maxForks = { params.parallel_mode ? 2 : 1 }
            }
        }
    }

    test {
        process {
            executor = 'local'
            cpus = 2
            memory = '4 GB'
        }
        params {
            threads = 2
        }
    }
}

// Execution report settings
timeline {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_timeline.html"
}

report {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_report.html"
}

trace {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_trace.txt"
}

dag {
    enabled = true
    file = "${params.outdir}/pipeline_info/pipeline_dag.svg"
}

// Manifest
manifest {
    name = 'diann-workflow'
    author = 'karlssoc'
    description = 'Modular Nextflow workflow for DIA-NN mass spectrometry analysis'
    mainScript = 'main.nf'
    nextflowVersion = '>=21.04.0'
    version = '1.0.0'
}
